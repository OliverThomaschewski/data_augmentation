{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "___\n",
    "by Oliver Thomaschewski (Matrikelnummer) and Lisa-Marlen Wiegandt (572770)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link zur Pr√§sentation\n",
    "\n",
    "https://docs.google.com/presentation/d/1ynsTBfkaSOx5H7MoUForDk7t-b1NwtIKjco2gjHw7Zg/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content\n",
    "___\n",
    "1. [What is data augmentation](#What-is-data-augmentation)\n",
    "1. [Why use data augmentation](#why-use-data-augmentation)\n",
    "    2. Challenges\n",
    "    2. Use Cases\n",
    "1. [Example: Image augmentation](#Image-augmentation)\n",
    "    2. Simple transformations\n",
    "    2. Advanced techniques\n",
    "1. [Sources](#Sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is data augmentation\n",
    "___\n",
    "* artificially increase of data set\n",
    "* synthesizing new data from given data\n",
    "    * amount of data increased\n",
    "    * diversity of data increased\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why use data augmentation\n",
    "___\n",
    "* prediction accuracy based on amount and diversity of training data\n",
    "* therefore improving prediction (best case)\n",
    "* reducing cost of collecting and labeling data\n",
    "* preventing data privacy problems\n",
    "    \n",
    "#### Challenges\n",
    "* useful augmentation\n",
    "* needs to analyze output quality of augmentation\n",
    "* reproducing biases from original dataset  \n",
    "\n",
    "#### Use Cases\n",
    "\n",
    "* Small dataset for medical images, especially for rare diseases\n",
    "* due to data privacy regulations data is not given"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image augmentation\n",
    "___\n",
    "* simple alteration popular \n",
    "* or generation of new synthetic data with more advanced techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples of data augmentation with torchvision.transforms\n",
    "\n",
    "we start with one picture ##maybe htw picture ??????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Image\n",
    "\n",
    "orig_img = Image.open(Path(\"images/flower.png\"))\n",
    "img_width, img_height = orig_img.size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gray_img = T.Grayscale()(orig_img)\n",
    "gray_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hflip_img = T.functional.hflip(orig_img)\n",
    "vflip_img = T.functional.vflip(orig_img)\n",
    "\n",
    "display(hflip_img, vflip_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_img = T.functional.affine(orig_img, angle = 0, translate=[100 ,40], scale=1, shear=0)\n",
    "translate_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotate_img = T.functional.rotate(orig_img, angle = 30.0, interpolation = T.InterpolationMode.BICUBIC,fill = 100)\n",
    "rotate_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random affine\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_img = T.RandomAffine(degrees=(30,70), translate=(0.1, 0.3), scale=(1, 1.5))(orig_img)\n",
    "\n",
    "affine_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Center cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = 200\n",
    "\n",
    "crop_img = T.CenterCrop(crop_size)(orig_img)\n",
    "crop_img = T.Resize(img_height)(crop_img)\n",
    "crop_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_crop_img = T.RandomCrop(200)(orig_img)\n",
    "\n",
    "rand_crop_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blurred_img = T.GaussianBlur(kernel_size=(33,33), sigma=(2, 2))(orig_img) \n",
    "blurred_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers_img = T.RandomPerspective( p=1)(orig_img)\n",
    "pers_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_img = T.ElasticTransform(alpha= 100.0)(orig_img)\n",
    "elastic_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ColorJitter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter_img = T.ColorJitter(brightness = 0.5, contrast=0.5, saturation=0.5, hue=0.5)(orig_img)\n",
    "# HUE Sinnvoll?\n",
    "jitter_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Augment  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_img = T.RandAugment(num_ops=5)(orig_img)\n",
    "rand_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = T.Compose([\n",
    "    T.CenterCrop(200),\n",
    "    T.Grayscale(),\n",
    "    T.Resize(img_width)\n",
    "])\n",
    "\n",
    "img = transforms(orig_img)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "To get a referenc eon the training data and from there on, tweak the used algorithm and training data to try to achieve better results than the baseline model\n",
    "\n",
    "1. Use Baseline model with exisiting Data Set\n",
    "2. Get Benchmark values\n",
    "3. Add one kind of data Augmentation ( flipping, blurr, grayscale)\n",
    "4. Decide / Try if Data Augmentation gives better results than baseline model.\n",
    "5. Repeat 3 & 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "first \n",
    "https://www.mygreatlearning.com/blog/understanding-data-augmentation/\n",
    "https://research.aimultiple.com/data-augmentation/\n",
    "\n",
    "second\n",
    "https://snapstack.cz/data-augmentation-advantages-challenges-and-instances/\n",
    "https://research.aimultiple.com/data-augmentation/\n",
    "\n",
    "third\n",
    "https://towardsdatascience.com/a-comprehensive-guide-to-image-augmentation-using-pytorch-fb162f2444be\n",
    "\n",
    "mehr\n",
    "\n",
    "https://nanonets.com/blog/data-augmentation-how-to-use-deep-learning-when-you-have-limited-data-part-2/\n",
    "\n",
    "Baseline Models:<br>\n",
    "https://towardsdatascience.com/baseline-models-your-guide-for-model-building-1ec3aa244b8d <br>\n",
    "https://towardsai.net/p/l/what-are-baseline-models-and-benchmarking-for-machine-learning-why-we-need-them\n",
    "\n",
    "get_transforms in fastai\n",
    "\n",
    "https://towardsdatascience.com/image-classification-baseline-model-for-2020-1d33f0986fc0\n",
    "\n",
    "pytorch transformations:\n",
    "\n",
    "https://pytorch.org/vision/stable/transforms.html\n",
    "\n",
    "Always start stupid:\n",
    "\n",
    "https://blog.insightdatascience.com/always-start-with-a-stupid-model-no-exceptions-3a22314b9aaa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "75993ab2b49036cadd476b97bc353bfc628d81ff23efd854332b94743c4a2258"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
